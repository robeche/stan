\chapter{Arquitectura del Sistema}
%================================================

\section{Visión General}

El sistema implementa una \textbf{arquitectura modular} cuyo objetivo principal es permitir trabajar, mejorar y actualizar cada uno de los módulos de manera \textbf{totalmente independiente}. Esta filosofía de diseño garantiza que los cambios en un componente no afecten al funcionamiento de los demás, facilitando el mantenimiento evolutivo y la escalabilidad del sistema.

La arquitectura gestiona el ciclo completo de un pipeline RAG (Retrieval-Augmented Generation), desde la ingesta de documentos hasta la generación de respuestas conversacionales, manteniendo siempre el principio de \textbf{separación de responsabilidades} donde cada módulo tiene un propósito específico, interfaces bien definidas y puede evolucionar autónomamente.

\subsection{Principio de Modularidad}

La arquitectura se basa en los siguientes principios fundamentales:

\begin{itemize}
    \item \textbf{Independencia funcional}: Cada módulo puede desarrollarse, probarse y desplegarse de forma independiente
    \item \textbf{Interfaces estándar}: Los módulos se comunican mediante interfaces bien definidas (APIs, protocolos de mensajería)
    \item \textbf{Bajo acoplamiento}: Los cambios en un módulo no requieren modificaciones en otros módulos
    \item \textbf{Alta cohesión}: Cada módulo agrupa funcionalidades relacionadas en una única responsabilidad
    \item \textbf{Reemplazabilidad}: Cualquier módulo puede ser sustituido por una implementación alternativa que respete la misma interfaz
\end{itemize}

Esta arquitectura modular permite:

\begin{enumerate}
    \item \textbf{Actualización granular}: Cambiar el modelo de embeddings (BGE-M3 → BGE-large) sin afectar parsing o chunking
    \item \textbf{Mejora iterativa}: Optimizar el chunking semántico sin impactar la generación de respuestas del LLM
    \item \textbf{Experimentación segura}: Probar nuevos modelos de parsing (Nemotron → Tesseract) en paralelo con el sistema productivo
    \item \textbf{Mantenimiento simplificado}: Corregir bugs en un módulo sin riesgo de regresiones en otros
    \item \textbf{Escalado selectivo}: Escalar horizontalmente solo los módulos que lo requieran (ej: más workers de embedding)
\end{enumerate}

\subsection{Componentes Principales}

La arquitectura se organiza en tres capas fundamentales:

\subsubsection{Capa de Presentación}

Compuesta por dos aplicaciones web Django independientes:

\begin{itemize}
    \item \textbf{Admin Panel}: Interfaz de administración para la gestión del ciclo de vida de los documentos. Permite subir archivos, monitorear el progreso del procesamiento, visualizar contenido extraído (páginas, imágenes, tablas) y explorar los chunks generados. Requiere autenticación de administrador.
    
    \item \textbf{Chatbot}: Interfaz pública conversacional que permite a los usuarios realizar consultas en lenguaje natural. No requiere autenticación y proporciona respuestas contextuales basadas en los documentos indexados, incluyendo referencias visuales automáticas.
\end{itemize}

\subsubsection{Capa de Coordinación y Orquestación}

Esta capa actúa como el núcleo del sistema, gestionando las peticiones de los usuarios y coordinando la ejecución de las diferentes tareas:

\begin{itemize}
    \item \textbf{Django Core}: Framework web que gestiona la aplicación. Controla el flujo de las peticiones HTTP, maneja los modelos de datos, renderiza las vistas y define las rutas (URLs). Actúa como punto de entrada y coordinador principal del sistema.
    
    \item \textbf{Celery Worker}: Sistema de tareas asíncronas que ejecuta procesos largos en segundo plano (como parsing de documentos, generación de embeddings, etc.) sin que el usuario tenga que esperar. Permite que la interfaz web permanezca rápida y responsive.
    
    \item \textbf{Redis}: Sistema de almacenamiento en memoria que cumple dos funciones: (1) gestiona la cola de tareas pendientes para Celery, y (2) almacena datos temporales y resultados intermedios para acceso rápido, mejorando el rendimiento general del sistema.
\end{itemize}

\subsubsection{Capa de Procesamiento y Almacenamiento}

Esta capa contiene los módulos especializados y sistemas de persistencia:

\begin{itemize}
    \item \textbf{Módulos de Procesamiento RAG}:
    \begin{itemize}
        \item \textit{Parsing (Nemotron)}: Extrae texto estructurado, imágenes y tablas de documentos
        \item \textit{Chunking}: Divide el contenido en fragmentos semánticos optimizados
        \item \textit{Embeddings (BGE-M3)}: Genera representaciones vectoriales de 1024 dimensiones
    \end{itemize}
    
    \item \textbf{Sistemas de Almacenamiento}:
    \begin{itemize}
        \item \textit{SQLite}: Base de datos relacional para metadatos, estado de procesamiento y relaciones
        \item \textit{ChromaDB}: Base de datos vectorial para búsqueda semántica eficiente
    \end{itemize}
    
    \item \textbf{Modelo de Lenguaje}:
    \begin{itemize}
        \item \textit{Ollama}: Servidor LLM local que genera respuestas contextuales basadas en los chunks recuperados
    \end{itemize}
\end{itemize}

\subsection{Flujo de Datos}

El sistema maneja dos flujos de datos principales:

\begin{enumerate}
    \item \textbf{Flujo de Ingesta}: Admin Panel → Django → Celery → Módulos RAG → Almacenamiento
    \item \textbf{Flujo de Consulta}: Usuario → Chatbot → Embedding → ChromaDB → Ollama → Respuesta
\end{enumerate}

\subsection{Características Arquitectónicas}

\begin{itemize}
    \item \textbf{Modularidad}: Cada componente es totalmente independiente y puede ser desarrollado, probado, mejorado o reemplazado sin afectar al resto del sistema
    \item \textbf{Procesamiento Asíncrono}: Las tareas pesadas se ejecutan en background mediante Celery, manteniendo la interfaz responsiva
    \item \textbf{Aceleración por GPU}: Los modelos de embedding y parsing utilizan CUDA cuando está disponible, pero pueden funcionar en CPU como fallback
    \item \textbf{Escalabilidad Horizontal}: Los workers de Celery pueden ejecutarse en múltiples máquinas de forma independiente
    \item \textbf{Persistencia Dual}: Combina bases de datos relacional y vectorial, cada una optimizada para su propósito específico
    \item \textbf{Tolerancia a fallos}: El fallo de un módulo no compromete la operación de los demás (ej: si ChromaDB falla, el Admin Panel sigue funcionando)
\end{itemize}

\begin{figure}[h]
\centering
\begin{tikzpicture}[
    node distance=1.5cm,
    block/.style={rectangle, draw, fill=blue!20, text width=5em, text centered, rounded corners, minimum height=3em},
    service/.style={rectangle, draw, fill=green!20, text width=6em, text centered, rounded corners, minimum height=3em},
    storage/.style={cylinder, draw, fill=orange!20, shape border rotate=90, aspect=0.25, text width=4em, text centered, minimum height=3em},
    arrow/.style={-Stealth, thick}
]

% Frontend
\node[block] (user) {Usuario};

% Django Apps
\node[block, below=of user, xshift=-3cm] (admin) {Admin Panel};
\node[block, below=of user, xshift=3cm] (chatbot) {Chatbot};

% Django Core
\node[service, below=of user, yshift=-3cm] (django) {Django Core};

% Background Services
\node[service, below left=of django, yshift=-1cm] (celery) {Celery Worker};
\node[service, below right=of django, yshift=-1cm] (redis) {Redis};

% Processing Modules
\node[block, below=of celery, yshift=-1cm, xshift=-2cm] (parse) {Parsing\\(Nemotron)};
\node[block, below=of celery, yshift=-1cm] (chunk) {Chunking};
\node[block, below=of celery, yshift=-1cm, xshift=2cm] (embed) {Embeddings\\(BGE-M3)};

% Storage
\node[storage, below=of chunk, yshift=-2cm, xshift=-2cm] (sqlite) {SQLite};
\node[storage, below=of chunk, yshift=-2cm, xshift=2cm] (chroma) {ChromaDB};

% LLM
\node[service, right=of chatbot, xshift=1cm] (ollama) {Ollama\\LLM};

% Arrows
\draw[arrow] (user) -- (admin);
\draw[arrow] (user) -- (chatbot);
\draw[arrow] (admin) -- (django);
\draw[arrow] (chatbot) -- (django);
\draw[arrow] (django) -- (celery);
\draw[arrow] (django) -- (redis);
\draw[arrow] (celery) -- (parse);
\draw[arrow] (parse) -- (chunk);
\draw[arrow] (chunk) -- (embed);
\draw[arrow] (embed) -- (chroma);
\draw[arrow] (celery) -- (sqlite);
\draw[arrow] (chatbot) -- (chroma);
\draw[arrow] (chatbot) -- (ollama);

\end{tikzpicture}
\caption{Arquitectura general del sistema}
\end{figure}

\section{Flujo de Procesamiento de Documentos}

\begin{figure}[h]
\centering
\begin{tikzpicture}[
    node distance=2cm,
    stage/.style={rectangle, draw, fill=blue!30, text width=8em, text centered, rounded corners, minimum height=2.5em},
    decision/.style={diamond, draw, fill=yellow!30, text width=6em, text centered, aspect=2},
    arrow/.style={-Stealth, thick}
]

\node[stage] (upload) {1. Subida\\de Documento};
\node[stage, below=of upload] (parse) {2. Parsing\\(Nemotron)};
\node[stage, below=of parse] (extract) {3. Extracción\\Páginas/Imágenes/Tablas};
\node[stage, below=of extract] (chunk) {4. Chunking\\Semántico};
\node[stage, below=of chunk] (embed) {5. Generación\\Embeddings (GPU)};
\node[stage, below=of embed] (index) {6. Indexación\\ChromaDB};
\node[stage, below=of index] (complete) {7. Completado};

\draw[arrow] (upload) -- node[right] {Celery Task} (parse);
\draw[arrow] (parse) -- node[right] {JSON Output} (extract);
\draw[arrow] (extract) -- node[right] {Markdown + Media} (chunk);
\draw[arrow] (chunk) -- node[right] {Chunks Array} (embed);
\draw[arrow] (embed) -- node[right] {Vectors 1024D} (index);
\draw[arrow] (index) -- node[right] {Status Update} (complete);

\end{tikzpicture}
\caption{Pipeline de procesamiento de documentos}
\end{figure}

\section{Flujo de Consulta (Chatbot)}

\begin{figure}[h]
\centering
\begin{tikzpicture}[
    node distance=1.8cm,
    stage/.style={rectangle, draw, fill=green!30, text width=9em, text centered, rounded corners, minimum height=2.5em},
    arrow/.style={-Stealth, thick}
]

\node[stage] (query) {1. Pregunta del Usuario};
\node[stage, below=of query] (embed) {2. Embedding de la Query\\(BGE-M3)};
\node[stage, below=of embed] (search) {3. Búsqueda Vectorial\\(ChromaDB)};
\node[stage, below=of search] (retrieve) {4. Recuperar Top-K Chunks};
\node[stage, below=of retrieve] (context) {5. Construir Contexto\\+ Referencias};
\node[stage, below=of context] (llm) {6. Generación LLM\\(Ollama)};
\node[stage, below=of llm] (postprocess) {7. Post-Procesamiento\\Inyección de Imágenes};
\node[stage, below=of postprocess] (response) {8. Respuesta Final\\+ Fuentes};

\draw[arrow] (query) -- (embed);
\draw[arrow] (embed) -- node[right] {Vector 1024D} (search);
\draw[arrow] (search) -- node[right] {Chunk IDs} (retrieve);
\draw[arrow] (retrieve) -- node[right] {Chunks + Metadata} (context);
\draw[arrow] (context) -- node[right] {Prompt} (llm);
\draw[arrow] (llm) -- node[right] {Text + Referencias} (postprocess);
\draw[arrow] (postprocess) -- node[right] {HTML + Images} (response);

\end{tikzpicture}
\caption{Pipeline de consulta del chatbot}
\end{figure}

%================================================

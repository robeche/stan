# MÃ³dulo de Reranking para Sistema RAG

Sistema de reranking con modelos cross-encoder para mejorar la precisiÃ³n de bÃºsquedas vectoriales.

## ğŸ¯ Â¿QuÃ© es Reranking?

El reranking es un **segundo paso de refinamiento** despuÃ©s de la bÃºsqueda vectorial inicial:

```
Query â†’ Embedding â†’ ChromaDB (top 20) â†’ Reranker â†’ Top 5 mÃ¡s relevantes â†’ LLM
         â†“                                   â†“
    Bi-encoder                         Cross-encoder
    (rÃ¡pido, menos preciso)            (lento, mÃ¡s preciso)
```

**Por quÃ© funciona:**
- **Bi-encoder** (BGE-M3): Query y documento se codifican por separado â†’ comparaciÃ³n rÃ¡pida pero bÃ¡sica
- **Cross-encoder** (Reranker): Query + documento se analizan **juntos** â†’ entiende relaciones, mÃ¡s preciso

## ğŸ¯ CaracterÃ­sticas

- âœ… **Mejora 10-20%** la precisiÃ³n del retrieval
- âœ… **MÃºltiples modelos** (BGE, MS-MARCO, multilingÃ¼es)
- âœ… **IntegraciÃ³n directa** con VectorStore
- âœ… **AnÃ¡lisis de cambios** de ranking
- âœ… **GPU/CPU** automÃ¡tico
- âœ… **API simple** y fÃ¡cil de usar

## ğŸ“¦ InstalaciÃ³n

```bash
pip install sentence-transformers torch
```

Ya instalado si tienes el mÃ³dulo de embeddings.

## ğŸš€ Uso BÃ¡sico

### Ejemplo 1: Reranking simple

```python
from vector_store import VectorStore
from embedding_generator import EmbeddingGenerator
from reranker import Reranker

# Setup
store = VectorStore(persist_directory="output_rag/chroma_db")
generator = EmbeddingGenerator("bge-m3")
reranker = Reranker("bge-reranker-v2-m3")

# Query
query = "What are the blade specifications?"
query_emb = generator.generate_embedding(query)

# 1. BÃºsqueda vectorial (recuperar mÃ¡s candidatos)
results = store.query_by_embedding(
    query_embedding=query_emb,
    n_results=20  # MÃ¡s de lo que necesitas
)

# 2. Reranking (obtener los mejores)
reranked = reranker.rerank_results(
    query=query,
    search_results=results,
    top_k=5,  # Top 5 finales
    return_full_results=True
)

# 3. Usar resultados refinados
for i, result in enumerate(reranked, 1):
    print(f"{i}. {result.id}")
    print(f"   Score: {result.rerank_score:.4f}")
    print(f"   Rank change: {result.rank_change:+d}")
```

### Ejemplo 2: Comparar con/sin reranking

```python
# Sin reranking
normal_results = store.query_by_embedding(query_emb, n_results=5)

# Con reranking
search_results = store.query_by_embedding(query_emb, n_results=20)
reranked_results = reranker.rerank_results(
    query=query,
    search_results=search_results,
    top_k=5
)

print("SIN RERANKING:")
for r in normal_results['results']:
    print(f"{r['id']}: {r['similarity']:.4f}")

print("\nCON RERANKING:")
for r in reranked_results['results']:
    print(f"{r['id']}: {r['rerank_score']:.4f} (cambio: {r['rank_change']:+d})")
```

## ğŸ¤– Modelos Disponibles

### BGE Rerankers (BAAI - Recomendados)

```python
# Mejor para RAG (multilingÃ¼e, Ãºltima generaciÃ³n)
reranker = Reranker("bge-reranker-v2-m3")
# - Max length: 8192 tokens
# - MultilingÃ¼e
# - Performance: â­â­â­â­â­

# Balance rendimiento/velocidad
reranker = Reranker("bge-reranker-base")
# - Max length: 512 tokens
# - InglÃ©s
# - Performance: â­â­â­â­

# MÃ¡xima precisiÃ³n
reranker = Reranker("bge-reranker-large")
# - Max length: 512 tokens
# - InglÃ©s
# - Performance: â­â­â­â­â­
```

### MS-MARCO (RÃ¡pidos)

```python
# Velocidad mÃ¡xima
reranker = Reranker("ms-marco-mini")

# Balance
reranker = Reranker("ms-marco-small")
```

### Listar modelos

```python
modelos = Reranker.list_available_models()
for alias, full_name in modelos.items():
    info = Reranker.get_model_info(alias)
    print(f"{alias}: {info['best_for']}")
```

## ğŸ”§ API Completa

### InicializaciÃ³n

```python
reranker = Reranker(
    model_name="bge-reranker-v2-m3",  # Modelo a usar
    device="auto",                     # 'auto', 'cuda', 'cpu'
    batch_size=32,                     # Batch para procesamiento
    show_progress=False                # Mostrar barra de progreso
)
```

### Reranking bÃ¡sico

```python
# Reordenar lista de documentos
indexed_scores = reranker.rerank(
    query="blade design",
    documents=["doc1", "doc2", "doc3"],
    top_k=2  # Opcional, None = todos
)
# Retorna: [(idx, score), (idx, score), ...]
```

### Reranking de resultados de bÃºsqueda

```python
# Formato completo
reranked = reranker.rerank_results(
    query="blade specifications",
    search_results=results,           # De VectorStore
    top_k=5,                          # NÃºmero final
    return_full_results=True          # Objetos RerankResult
)

# Formato compatible con VectorStore
reranked_dict = reranker.rerank_results(
    query="blade specifications",
    search_results=results,
    top_k=5,
    return_full_results=False  # Diccionario
)
```

### Calcular scores directamente

```python
scores = reranker.score_pairs(
    query="turbine design",
    documents=["doc1", "doc2", "doc3"]
)
# Retorna: array([0.85, 0.42, 0.91])
```

## ğŸ“Š Objeto RerankResult

Cuando `return_full_results=True`:

```python
@dataclass
class RerankResult:
    id: str                # ID del documento
    document: str          # Texto completo
    metadata: Dict         # Metadata del chunk
    original_score: float  # Score de bÃºsqueda vectorial
    rerank_score: float    # Score del reranker
    rank_change: int       # Cambio de posiciÃ³n (+ = subiÃ³, - = bajÃ³)
```

Ejemplo de uso:

```python
for result in reranked:
    if result.rank_change > 0:
        print(f"â†‘ {result.id} subiÃ³ {result.rank_change} posiciones")
        print(f"  Score mejorÃ³ de {result.original_score:.4f} a {result.rerank_score:.4f}")
```

## ğŸ¯ Estrategias de Uso

### Estrategia 1: Two-Stage Retrieval (Recomendada)

```python
# Recuperar muchos candidatos
candidates = store.query_by_embedding(query_emb, n_results=50)

# Refinar a los mejores
final = reranker.rerank_results(query, candidates, top_k=5)
```

**Ventajas:**
- âœ… Combina velocidad (bi-encoder) con precisiÃ³n (cross-encoder)
- âœ… Explora mÃ¡s del espacio de bÃºsqueda
- âœ… Mejor recall y precision

### Estrategia 2: Reranking Selectivo

```python
# Solo rerank si la confianza es baja
results = store.query_by_embedding(query_emb, n_results=10)

top_score = results['results'][0]['similarity']

if top_score < 0.7:  # Confianza baja
    results = reranker.rerank_results(query, results, top_k=5)
else:
    results = results['results'][:5]  # Usar directos
```

### Estrategia 3: MÃºltiples Queries

```python
# Para queries complejas, dividir y rerank
sub_queries = [
    "blade design",
    "tower specifications", 
    "power capacity"
]

all_chunks = {}
for sq in sub_queries:
    emb = generator.generate_embedding(sq)
    results = store.query_by_embedding(emb, n_results=20)
    reranked = reranker.rerank_results(sq, results, top_k=3)
    
    for r in reranked:
        if r.id not in all_chunks:
            all_chunks[r.id] = r
        else:
            # Mantener mejor score
            if r.rerank_score > all_chunks[r.id].rerank_score:
                all_chunks[r.id] = r

# Top chunks consolidados
final = sorted(all_chunks.values(), 
               key=lambda x: x.rerank_score, 
               reverse=True)[:5]
```

## ğŸ“Š AnÃ¡lisis de Resultados

### Visualizar cambios

```python
reranked = reranker.rerank_results(
    query=query,
    search_results=results,
    top_k=10,
    return_full_results=True
)

# Analizar movimientos
moved_up = [r for r in reranked if r.rank_change > 0]
moved_down = [r for r in reranked if r.rank_change < 0]

print(f"Subieron: {len(moved_up)}")
print(f"Bajaron: {len(moved_down)}")

# Mayor cambio
max_change = max(reranked, key=lambda x: abs(x.rank_change))
print(f"Mayor cambio: {max_change.id} ({max_change.rank_change:+d})")
```

### Calcular mejora

```python
# Mejora promedio de score
improvements = [
    r.rerank_score - r.original_score 
    for r in reranked
]
avg_improvement = sum(improvements) / len(improvements)
print(f"Mejora promedio: {avg_improvement:+.4f}")

# Documentos con mayor mejora
top_improved = sorted(
    reranked,
    key=lambda x: x.rerank_score - x.original_score,
    reverse=True
)[:3]

for r in top_improved:
    improvement = r.rerank_score - r.original_score
    print(f"{r.id}: {improvement:+.4f}")
```

## ğŸ–¥ï¸ LÃ­nea de Comandos

```bash
# Listar modelos disponibles
python reranker.py --list-models

# Reranking desde archivo
python reranker.py "blade design" results.json \
  --model bge-reranker-v2-m3 \
  --top-k 5 \
  --device cuda
```

Formato de `results.json`:
```json
{
  "results": [
    {
      "id": "chunk_0001",
      "document": "text...",
      "metadata": {...},
      "similarity": 0.85
    }
  ]
}
```

## ğŸ“ˆ Performance

### Benchmarks (24 chunks, GPU RTX 5080)

| Modelo | Tiempo (top 20â†’5) | PrecisiÃ³n vs Sin Rerank |
|--------|-------------------|------------------------|
| bge-reranker-v2-m3 | ~150ms | +15-20% |
| bge-reranker-base | ~80ms | +12-15% |
| ms-marco-small | ~50ms | +10-12% |

### ComparaciÃ³n con bÃºsqueda vectorial

```
BÃºsqueda vectorial sola:
  Query â†’ Embedding (20ms) â†’ ChromaDB (5ms) â†’ Top 5
  Total: ~25ms

Con reranking:
  Query â†’ Embedding (20ms) â†’ ChromaDB (5ms) â†’ Reranker (150ms) â†’ Top 5
  Total: ~175ms
  
Overhead: 150ms (6x mÃ¡s lento)
Ganancia: 15-20% mejor precisiÃ³n
```

**ConclusiÃ³n**: Vale la pena para queries importantes o cuando la precisiÃ³n es crÃ­tica.

## ğŸ” CuÃ¡ndo Usar Reranking

### âœ… Usar si:

- Dataset mediano/grande (>100 chunks)
- Queries complejas o ambiguas
- Necesitas mÃ¡xima precisiÃ³n
- Documentos muy similares entre sÃ­
- BÃºsquedas de producciÃ³n crÃ­ticas

### âŒ Puedes omitir si:

- Dataset muy pequeÃ±o (<50 chunks) â†’ bÃºsqueda directa suficiente
- Queries muy simples (keywords exactos)
- Restricciones estrictas de latencia (<100ms)
- Embeddings ya muy buenos (OpenAI, BGE-M3)
- Prototipo/desarrollo rÃ¡pido

## ğŸ’¡ Tips y Mejores PrÃ¡cticas

### OptimizaciÃ³n

```python
# âœ… Recuperar mÃ¡s candidatos para reranking
results = store.query(n_results=30)  # 3-5x lo que necesitas
final = reranker.rerank(results, top_k=10)

# âŒ Recuperar pocos candidatos
results = store.query(n_results=5)
final = reranker.rerank(results, top_k=5)  # Desperdicia reranker
```

### Batch processing

```python
# âœ… Procesar mÃºltiples queries en batch
queries = ["query1", "query2", "query3"]
for query in queries:
    # Reranker reutiliza modelo
    results = reranker.rerank_results(query, search_results, top_k=5)
```

### Caching

```python
# Para queries frecuentes, cachea resultados
cache = {}

def rerank_with_cache(query, results):
    if query in cache:
        return cache[query]
    
    reranked = reranker.rerank_results(query, results, top_k=5)
    cache[query] = reranked
    return reranked
```

## ğŸ› Troubleshooting

**P: Reranking muy lento**  
R:
- Verifica que estÃ¡s usando GPU (`device="cuda"`)
- Reduce `n_results` inicial (no mÃ¡s de 50)
- Usa modelo mÃ¡s pequeÃ±o (`ms-marco-mini`)

**P: Los rankings no cambian mucho**  
R: Normal si:
- Embeddings iniciales ya son muy buenos
- Dataset pequeÃ±o con chunks claros
- Query muy especÃ­fica

**P: Out of memory**  
R:
- Reduce `batch_size`
- Usa modelo mÃ¡s pequeÃ±o
- Procesa en batches mÃ¡s pequeÃ±os

**P: Resultados peores que sin reranking**  
R:
- Verifica que usas el mismo `query` texto (no embedding)
- AsegÃºrate que `search_results` tiene formato correcto
- Prueba modelo diferente

## ğŸ”— IntegraciÃ³n Pipeline RAG Completo

```python
# Pipeline completo: Chunking â†’ Embeddings â†’ VectorStore â†’ Reranking â†’ LLM

# 1. Setup
from vector_store import VectorStore
from embedding_generator import EmbeddingGenerator
from reranker import Reranker

store = VectorStore(persist_directory="output_rag/chroma_db")
generator = EmbeddingGenerator("bge-m3")
reranker = Reranker("bge-reranker-v2-m3")

# 2. Query
query = "What are the wind turbine specifications?"

# 3. Embedding
query_emb = generator.generate_embedding(query)

# 4. BÃºsqueda vectorial (candidatos)
search_results = store.query_by_embedding(
    query_embedding=query_emb,
    n_results=20
)

# 5. Reranking (refinamiento)
reranked = reranker.rerank_results(
    query=query,
    search_results=search_results,
    top_k=5,
    return_full_results=True
)

# 6. Construir contexto para LLM
context = "\n\n".join([
    f"[Document {i}]\n{r.document}"
    for i, r in enumerate(reranked, 1)
])

# 7. Generar respuesta (siguiente paso)
# response = llm.generate(query, context)
```

## ğŸ“š Recursos

- **Paper BGE-Reranker**: https://arxiv.org/abs/2309.07597
- **ChromaDB Docs**: https://docs.trychroma.com/
- **Reranking Guide**: https://www.pinecone.io/learn/reranking/

---

**Creado**: 2026-01-02  
**VersiÃ³n**: 1.0  
**Autor**: Sistema RAG
